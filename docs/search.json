[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "",
    "text": "Abstract. Research on how Bayesian VARs with regime change affect the forecasting of unemployment rate\nKeywords. bsvars, regime change, forecasting, R,"
  },
  {
    "objectID": "index.html#model",
    "href": "index.html#model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Model",
    "text": "Model\n\nHypothesis\nVar(p) model\n\\[\\begin{aligned}\ny_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 x_{1, t-1} + \\beta_3 x_{2, t-1} + \\ldots + \\beta_n x_{n, t-1} + \\varepsilon_t\n\\end{aligned}\\]\nVar(p) model with regime change, meaning time-varying parameters\n\\[\\begin{aligned}\ny_t &= \\beta_{0,S_t} + \\beta_{1,S_t} y_{t-1} + \\beta_{2,S_t} x_{1, t-1} + \\beta_{3,S_t} x_{2, t-1} + \\ldots + \\beta_{n,S_t} x_{n, t-1} + \\varepsilon_t \\\\\n\\end{aligned}\\]\nProbability of transitioning from one state to another\n\\[\\begin{aligned}\nP(S_t = j | S_{t-1} = i) &= \\pi_{ij}\n\\end{aligned}\\]\n\n\nMatrix form\n\\[\\begin{align*}\n\\mathbf{Y}_t = \\boldsymbol{\\beta}_{S_t} \\mathbf{X}_t + \\boldsymbol{E}_t\n\\end{align*}\\]\n\\[\\begin{align*}\n\\boldsymbol{E}_t\n\\sim MN(0_T, \\Sigma, I_T)\n\\end{align*}\\]\n\\begin{align*} \\mathbf{Y}_t & : \\text{Matrix of response variables} \\\\ \\boldsymbol{\\beta} & : \\text{Coefficient matrix corresponding to regime state} \\\\ S_t & : \\text{Regime state} \\\\ \\mathbf{X}_t & : \\text{Matrix of predictor variables} \\\\ \\boldsymbol{\\varepsilon}_t & : \\text{Error term vector} \\end{align*}\n\\begin{align*} \\mathbf{Y}_t = \\begin{pmatrix} \\text{Unemployment}_t \\\\ \\text{GDP}_t \\\\ \\text{WPI}_t \\\\ \\text{CashRate}_t \\\\ \\end{pmatrix} \\end{align*}\nThe model’s equations include time-varying parameters, such as the coefficients of lagged variables, which adapt to changing economic conditions."
  },
  {
    "objectID": "index.html#basic-model",
    "href": "index.html#basic-model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Basic Model",
    "text": "Basic Model\nThe model follows the Normal Inverse Wishart distribution.\nLikelihood function kernel \\[\\begin{align}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}}exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\}\n\\end{align}\\]\n\nMinnesota Prior distribution\nThe Minnesota prior is commonly used in Bayesian Vector Autoregression (BVAR) models due to its ability to impose shrinkage towards zero on the coefficients, effectively regularizing the estimation process. The Minnesota prior aligns effectively with the stylized fact of nonstationarity observed in macroeconomic variables.\n\\[\\begin{align*}\np(A, \\Sigma) = p(A \\mid \\Sigma) \\cdot p(\\Sigma) \\\\\nA \\mid \\Sigma \\sim \\text{MN}_{K \\times N} (\\underline{A}, \\Sigma, \\underline{V}) \\\\\n\\Sigma \\sim  \\text{IW}_{N} (\\underline{S}, \\underline{v})\\\\\n\\end{align*}\\]\nWith lags = 4 and N = 4\n\\[\\begin{align*}\n\\underline{A} = \\begin{bmatrix}\n\\mathbf{0}_{4 \\times 1} & \\mathbf{I}_{4} & \\mathbf{0}_{4 \\times (4-1)4}\n\\end{bmatrix}'\n= \\begin{bmatrix}\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\\end{bmatrix}'\n\\end{align*}\\]\nThe column-specific prior covariance of A \\[\\begin{align*}\n\\underline{V} &= \\text{diag}\\left( \\begin{bmatrix}\nk_2 & k_1(\\mathbf{p}^{-2} \\otimes 1'_4)\n\\end{bmatrix} \\right)\\\\\n\\mathbf{p} &= \\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n\\end{bmatrix}\n\\end{align*}\\] \\[\\begin{align*}\n& k_2 : \\text{overall shrinkage for the constant term} \\\\\n& k_1 : \\text{overall shrinkage levels for autoregressive slopes} \\\\\n\\end{align*}\\]\nPrior covariance matrix\n\\[\\begin{bmatrix}\nk_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & k_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & k_1 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & k_1 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & k_1 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & \\cdots & 0\\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{16}      \n\\end{bmatrix}\\]\n\n\nThe joint posterior distribution\n\\[\\begin{align*}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma|Y,X)p(A,\\Sigma) \\\\\n&= L(A,\\Sigma|Y,X)p(A|\\Sigma)p(\\Sigma)\n\\end{align*}\\]\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\} \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A}) \\underline{V}^{-1}(A-\\underline{A})]\\} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]\\}\n\\end{align}\\]\nThe full conditional joint posterior have the following form \\[\\begin{align}\np(A|Y,X,\\Sigma) &\\sim MN_{K \\times N}(\\overline{A}, \\Sigma,\\overline{V} ) \\\\\np(\\Sigma|Y,X) &\\sim IW_{N}(\\overline{S}, \\overline{v})\\\\\n\\\\\n\\overline{V} &= (X'X + \\underline{V}^{-1})^{-1} \\\\\n\\overline{A} &= \\overline{V}(X'Y+\\underline{V}^{-1}\\underline{A}) \\\\\n\\overline{v} &= T + \\underline{v} \\\\\n\\overline{S} &= \\underline{S}+Y'Y+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\\overline{A}'\n\\overline{V}^{-1}\\overline{A} \\\\\n\\end{align}\\]\n\n###############################################\n# Posterior draws Normal-inverse Wishart\n###############################################\nposterior_draws       = function (S, Y, X, A.prior, V.prior, S.prior, nu.prior){\n    # Posterior parameters\n    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))\n    V.bar             = solve(V.bar.inv)\n    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n    nu.bar            = nrow(Y) + nu.prior\n    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior -\n                        t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv         = solve(S.bar)\n  \n    # Posterior draws \n    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n    Sigma.posterior   = apply(Sigma.posterior,3,solve)\n    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))\n    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))\n    L                 = t(chol(V.bar))\n    for (s in 1:S){\n      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])\n    }\n \n    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)\n    return(output)\n}\n\nS = 50000\nsample_minnesota        = posterior_draws(S, Y, X, A.prior, V.prior, S.prior, nu.prior)\nsample_minnesota_A      = sample_minnesota$A.posterior\nsample_minnesota_Sigma  = sample_minnesota$Sigma.posterior\n# sample_minnesota = posterior_draws(1000, Y, X, A.prior, V.prior, S.prior, nu.prior)"
  },
  {
    "objectID": "index.html#extension-1-model",
    "href": "index.html#extension-1-model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Extension 1 Model",
    "text": "Extension 1 Model\nCointegration is when the non-stationary variables have an equilibrium long term relationship or a common trend. The model is extended to incorporate dummy-observation-prior, aiming to account for the potential cointegration amongst the variables, capturing the underlying economic relationships and dynamics.\nThis approach allows us to leverage both the observed data and additional information about the structural relationships among variables, leading to more accurate parameter estimation and potentially improved forecasting performance.\nDummy observation prior also known as known as “sum-of-coefficients” proposed by Doan, Litterman, and Sims (1984) required a set of artificial observations for each variable.\n\\[\\begin{align*}\n\\underset{4\\times 4}y^{+} &= diag(\\frac{\\overline{y_0}}{\\mu}) \\\\\n\\underset{4 \\times (1+4\\times 4)}{x^{+}} &= [\\underset{n \\times 1}0,y^{+},...,y^{+}]\n\\end{align*}\\]\nTo be consistent with cointegration, an additional prior proposed by Sims (1993) is also added.\n\\[\\begin{align*}\n\\underset{1\\times 4}y^{++} &= \\frac{\\overline{y_0}^{'}}{\\delta}, ,   \\ i =1,2,3,4\\\\\n\\underset{1 \\times (1+4\\times 4)}{x^{++}} &= [\\frac{1}{\\delta},y^{++},...,y^{++}]\\\\\n\\end{align*}\\] \\[\\begin{align*}\n& \\overline{y_0} : \\text{average of the first 4 lag observations for each variable}\\\\\n& \\mu: \\text{controls variance }\\\\\n& \\delta: \\text{controls the tightness of the prior}\n\\end{align*}\\]\nFrom the above, the following matrix form is created:\n\\[\\begin{align*}\nY^{+} & = \\begin{bmatrix} y^+ \\\\ y^{++}\\end{bmatrix}', X^{+}  = \\begin{bmatrix} x^+ \\\\ x^{++}\\end{bmatrix}'\\\\\nY^{+} & = X^{+}A+E^{+} \\\\\nY^{+} & = \\begin{bmatrix}\n\\frac{\\overline{y_0}_1}{\\mu} & 0 & 0 & 0 \\\\\n0 & \\frac{\\overline{y_0}_2}{\\mu} & 0 & 0 \\\\\n0 & 0 & \\frac{\\overline{y_0}_3}{\\mu} & 0 \\\\\n0 & 0 & 0 & \\frac{\\overline{y_0}_4}{\\mu} \\\\\n\\frac{\\overline{y_0}_1}{\\delta} & \\frac{\\overline{y_0}_2}{\\delta} & \\frac{\\overline{y_0}_3}{\\delta} & \\frac{\\overline{y_0}_4}{\\delta} \\\\\n\\end{bmatrix}\n\\end{align*}\\]\n\\[\\begin{align*}\nX^{+} = \\begin{bmatrix}\n0 & \\frac{\\overline{y_0}_1}{\\mu} & 0 & 0 & 0 & \\cdots & 0 \\\\\n0 & 0 & \\frac{\\overline{y_0}_2}{\\mu} & 0 & 0 & \\cdots & 0 \\\\\n0 & 0 & 0 & \\frac{\\overline{y_0}_3}{\\mu} & 0 & \\cdots & 0 \\\\\n0 & 0 & 0 & 0 & \\frac{\\overline{y_0}_4}{\\mu} & \\cdots & \\frac{\\overline{y_0}_4}{\\mu} \\\\\n\\frac{1}{\\delta} & \\frac{\\overline{y_0}_1}{\\delta} & \\frac{\\overline{y_0}_2}{\\delta} & \\frac{\\overline{y_0}_3}{\\delta} & \\frac{\\overline{y_0}_4}{\\delta} & \\cdots & \\frac{\\overline{y_0}_4}{\\delta} \\\\\n\\end{bmatrix}\n\\end{align*}\\]\nThe prior distribution is\n\\[\\begin{align*}\nA \\mid \\Sigma &\\sim \\text{MN}_{K \\times N} (\\underline{A}^{+}, \\Sigma, \\underline{V}^{+}) \\\\\n\\Sigma &\\sim  \\text{IW}_{N} (\\underline{S}^{+}, \\underline{v}^{+})\\\\\n\\\\\n\\underline{A}^{+} &= (X^{+'}X )^{-1}X^{+'}Y^{+} \\\\\n\\underline{V}^{+} &= (X^{+'}X )^{-1} \\\\\n\\underline{v}^{+} &= T^{+} - K - N - 1\\\\\n\\underline{S}^{+} &= (Y^{+}-X^{+}\\underline{A}^{+})^{'}(Y^{+}-X^{+}\\underline{A}^{+})\\\\\n\\end{align*}\\]\n\nMinnesota and dummy observation prior distribution\nThe newly created matrix specified the model has 5 dummy observations. The above prior distribution is likely to encounter the problem of not having enough observations and lead to many challenges to meet the requirements for degree of freedom or invertibility of matrices. To resolve this, the combination of specifying the prior through both Normal inverse Wishart and dummy-observations is proposed, which is detived similarly to the posterior distribution in the basic model.\n\\[\\begin{align*}\nA \\mid \\Sigma &\\sim \\text{MN}_{K \\times N} (\\widetilde{A}, \\Sigma, \\widetilde{V}) \\\\\n\\Sigma &\\sim  \\text{IW}_{N} (\\widetilde{S}, \\widetilde{v})\\\\\n\\\\\n\\widetilde{A} &= \\widetilde{V}(X^{+'}Y^{+}+\\underline{V}^{-1}\\underline{A}) \\\\\n\\widetilde{V} &= (X^{+'}X^{+} + \\underline{V}^{-1})^{-1} \\\\\n\\widetilde{v} &= T^{+} + \\underline{v} \\\\\n\\widetilde{S} &= \\underline{S}+Y^{+'}Y^{+}+\\underline{A}'\\underline{V}^{-1}\\underline{A} -\\widetilde{A}'\\widetilde{V}^{-1}\\widetilde{A} \\\\\n\\end{align*}\\]\nThe full conditional joint posterior have the following form \\[\\begin{align}\np(A|Y,X,\\Sigma) &\\sim MN_{K \\times N}(\\overline{A}, \\Sigma,\\overline{V} ) \\\\\np(\\Sigma|Y,X) &\\sim IW_{N}(\\overline{S}, \\overline{v})\\\\\n\\\\\n\\overline{V} &= (X'X + \\widetilde{V}^{-1})^{-1} \\\\\n\\overline{A} &= \\overline{V}(X'Y+\\widetilde{V}^{-1}\\widetilde{A}) \\\\\n\\overline{v} &= T + \\widetilde{v} \\\\\n\\overline{S} &= \\widetilde{S}+Y'Y+\\widetilde{A}'\\widetilde{V}^{-1}\\widetilde{A}-\\overline{A}'\n\\overline{V}^{-1}\\overline{A} \\\\\n\\end{align}\\]\n\n###############################################\n# Posterior draws for dummy prior\n###############################################\nposterior_draws_dummy = function(S, Y, X, A.prior, V.prior, S.prior, nu.prior) {\n  \n  N       = ncol(Y)\n  p       = (ncol(X) - 1)/N\n  mu      = 1000\n  delta   = 1000\n  dim(X)\n  avg_unmp &lt;- mean(X[1, c(2, 6, 10, 14)])\n  avg_gdp &lt;- mean(X[1, c(3, 7, 11, 15)])\n  avg_wpi &lt;- mean(X[1, c(4, 8, 12, 16)])\n  avg_cash &lt;- mean(X[1, c(5, 9, 13, 17)])\n  \n  diag_mu &lt;- diag(c(avg_unmp/mu, avg_gdp/mu, avg_wpi/mu, avg_cash/mu))\n  row_delta &lt;-  matrix(c(avg_unmp/delta, avg_gdp/delta, avg_wpi/delta, avg_cash/delta), nrow = 1)\n  \n  Y_d       = rbind(diag_mu, row_delta)\n  \n  first_vector &lt;- matrix(c(0,0,0,0, 1/delta), ncol = 1)\n  X_d      = cbind(first_vector, Y_d, Y_d, Y_d, Y_d)\n  \n  # Normal-inverse Wishart combination of specifying the prior \n  ############################################################\n  V.tilde.inv   = t(X_d)%*%X_d + diag(1/diag(V.prior))\n  V.tilde       = solve(V.tilde.inv)\n  A.tilde       = V.tilde%*%(t(X_d)%*%Y_d + diag(1/diag(V.prior))%*%A.prior)\n  nu.tilde      = nrow(Y_d) + nu.prior\n  S.tilde       = S.prior + t(Y_d)%*%Y_d + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior -\n    t(A.tilde)%*%V.tilde.inv%*%A.tilde\n  S.tilde.inv   = solve(S.tilde)\n\n  # Normal-inverse Wishart posterior parameters\n  V.bar.inv   = t(X)%*%X + diag(1/diag(V.tilde))\n  V.bar       = solve(V.bar.inv)\n  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.tilde))%*%A.tilde)\n  nu.bar      = nrow(Y) + nu.tilde\n  S.bar       = S.tilde + t(Y)%*%Y + t(A.tilde)%*%diag(1/diag(V.tilde))%*%A.tilde -\n                t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv   = solve(S.bar)\n  \n\n  # Posterior draws \n  Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n  Sigma.posterior   = apply(Sigma.posterior,3,solve)\n  Sigma.posterior   = array(Sigma.posterior,c(N,N,S))\n  A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))\n  L                 = t(chol(V.bar))\n  for (s in 1:S){\n    A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])\n    }\n  output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)\n  return(output)\n}\nS = 50000\nsample_dummy        = posterior_draws_dummy(S, Y, X, A.prior, V.prior, S.prior, nu.prior)\nsample_dummy_A      = sample_dummy$A.posterior\nsample_dummy_Sigma  = sample_dummy$Sigma.posterior"
  },
  {
    "objectID": "index.html#model-proof",
    "href": "index.html#model-proof",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Model Proof",
    "text": "Model Proof\n1000 observations are simulated from a bi-variate Gaussian random walk process annd is used as data for the below proofs.\n\nBasic model\n\n\n\n\nPosterior mean of autoregressive\n\n\n1\n2\n\n\n\n\n0.077215\n-0.005406\n\n\n0.994250\n-0.000284\n\n\n0.001799\n0.996006\n\n\n\n\n\n\n\n\n\n\nPosterior mean of covarince\n\n\n1\n2\n\n\n\n\n0.980363\n0.002589\n\n\n0.002589\n1.036363\n\n\n\n\n\n\n\n\n\n\nExtended model"
  },
  {
    "objectID": "index.html#basic-model-2",
    "href": "index.html#basic-model-2",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Basic model",
    "text": "Basic model\n\n# Set up\n# Define colors\nmcxs1  = \"#05386B\"\nmcxs2  = \"#379683\"\nmcxs3  = \"#5CDB95\"\nmcxs4  = \"#8EE4AF\"\nmcxs5  = \"#EDF5E1\"\n\nmcxs1.rgb   = col2rgb(mcxs1)\nmcxs1.shade1= rgb(mcxs1.rgb[1],mcxs1.rgb[2],mcxs1.rgb[3], alpha=50, maxColorValue=255)\nmcxs2.rgb   = col2rgb(mcxs2)\nmcxs2.shade1= rgb(mcxs2.rgb[1],mcxs2.rgb[2],mcxs2.rgb[3], alpha=50, maxColorValue=255)\n\n############################################################\n# Point forecasts 2D plot\nforecast_plots &lt;- function(Y, Y.h, h, theta = 180, phi = 15.5, xlim = c(-100, 100)) {\n  \npoint_forecast    = apply(Y.h[,1,],1,mean) \ninterval_forecast = apply(Y.h[,1,],1,hdi,credMass=0.90)\ninterval_forecast_1 = apply(Y.h[,1,],1,hdi,credMass=0.68)\nrange             = range(Y[,1],interval_forecast)\n\npar(mfrow=c(1,1), mar=rep(3,4),cex.axis=1)\nplot(1:(length(Y[,1])), Y[,1], type=\"l\", axes=FALSE, \n     xlim = c(1, nrow(Y)+h), ylim=range, \n     xlab=\"\", ylab=\"\", \n     lwd=2, col = mcxs1)\nlines(length(Y[,1]):(length(Y[,1]) + h), c(Y[nrow(Y), 1],point_forecast), type=\"l\", \n      xlim =nrow(Y)+h+5, ylim=range,\n      xlab=\"\", ylab=\"\", \n      lwd=2, col = mcxs2)\naxis(1,c(3,23,43,63,83,101,nrow(Y), nrow(Y)+h),\n     c(\"1999\",\"2003\",\"2008\",\"20013\",\"2018\",\"2023\",\"\", \"2034\"), \n     col=\"black\")\naxis(2, at=seq(from=range[1], to=range[2], length.out=5), \n     labels=round(seq(from=range[1], to=range[2], length.out=5), 2),\n     col=\"black\")\nend_y_value &lt;- point_forecast[13] \nabline(h = end_y_value, col=\"red\", lty=2, lwd=1)\nabline(v = nrow(Y), col = \"black\")\nlegend(\"bottomleft\", legend=c(\"Data\", \"Forecast\"), \n       col=c(mcxs1, mcxs2), lty=c(1, 1), lwd=c(2, 2))\npolygon(c(length(Y[,1]):(length(Y[,1]) + h), (length(Y[,1]):(length(Y[,1]) + h))[(h+1):1]), \n        c(Y[nrow(Y), 1], interval_forecast[1,], interval_forecast[2,h:1], Y[nrow(Y), 1]), \n        col = mcxs1.shade1, border = mcxs1.shade1)\npolygon(c(length(Y[,1]):(length(Y[,1]) + h), (length(Y[,1]):(length(Y[,1]) + h))[(h+1):1]), \n        c(Y[nrow(Y), 1], interval_forecast_1[1,], interval_forecast_1[2,h:1], Y[nrow(Y), 1]), \n        col = mcxs1.shade1, border = mcxs1.shade1)\n\nlimits.1    = range(Y.h[,1,])\npoint.f     = apply(Y.h[,1,],1,mean)\ninterval.f  = apply(Y.h[,1,],1,hdi,credMass=0.90)\n\nx           = seq(from=limits.1[1], to=limits.1[2], length.out=100)\nz           = matrix(NA,h,99)\nfor (i in 1:h){\n  z[i,]     = hist(Y.h[i,1,], breaks=x, plot=FALSE)$density\n}\nx           = hist(Y.h[i,1,], breaks=x, plot=FALSE)$mids\nyy          = 1:h\nz           = t(z)\n\n\n  #range(limits.1[1], limits.1[2], interval.f[1, ], interval.f[2, ])\nylim &lt;- range(yy)\nzlim &lt;- range(z)\nf4    = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab=\"\\nunmp[t+h|t]\", ylab=\"h\",\n                zlab=\"\\npredictive densities of unemployment rate\", shade=NA, border=NA,\n                ticktype=\"detailed\", nticks=3,cex.lab=1, col=NA, plot=FALSE, \n                xlim = xlim)\nperspbox (x=x, y=yy, z=z, bty=\"f\", col.axis=\"black\", phi=phi, theta=theta,\n          xlab=\"\\nunemployment[t+h|t]\", ylab=\"h\", zlab=\"\\npredictive densities of unemployment\n          rate\", ticktype=\"detailed\", nticks=3,cex.lab=1, col = NULL, plot = TRUE, \n          xlim = xlim)\npolygon3D( x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), \n           col = mcxs1.shade1, NAcol = \"white\", border = NA, add = TRUE, plot = TRUE, \n           xlim = xlim)\nfor (i in 1:h){\n  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)\n  lines(f4.l, lwd=0.5, col=\"black\")\n}\nf4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)\nlines(f4.l1, lwd=2, col=mcxs1)\n}\n\nSimulate draws from the predictive density\n\n\n\n\nPosterior A means and sd table\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0.129096\n0.958734\n-0.023365\n0.056737\n-0.162965\n-0.037018\n0.002834\n0.014815\n0.157121\n-0.051699\n0.007576\n0.006393\n0.036105\n0.028995\n0.003053\n0.003599\n-0.001282\n\n\n3.344716\n0.119434\n0.341654\n0.364457\n0.111203\n0.132291\n0.205227\n0.207768\n0.147614\n0.102817\n0.140751\n0.140929\n0.109034\n0.078007\n0.106289\n0.106055\n0.072916\n\n\n0.004660\n0.005723\n0.998574\n-0.000514\n0.001195\n0.001216\n-0.000208\n-0.000057\n0.000557\n-0.002374\n-0.000049\n-0.000015\n-0.000616\n-0.001196\n0.000044\n-0.000037\n-0.001222\n\n\n0.109687\n0.003962\n0.011291\n0.012014\n0.003660\n0.004377\n0.006774\n0.006820\n0.004851\n0.003409\n0.004645\n0.004643\n0.003573\n0.002575\n0.003506\n0.003497\n0.002405\n\n\n\n\n\n\n\n\n\n\nPosterior Sigma means and sd table\n\n\n1\n2\n3\n4\n\n\n\n\n0.184862\n-0.002194\n-0.000112\n-0.031134\n\n\n0.026279\n0.000648\n0.000065\n0.016486\n\n\n-0.002194\n0.000201\n0.000004\n0.000537\n\n\n0.000648\n0.000028\n0.000002\n0.000533\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe plot of point forecast and density for 13 periods ahead, equivalent to 13 quarters or 3 years and 1 quarter from Q4 2023 to Q4 2026 shows a clear upward trend. The confidence interval is quite large. The unemployment rate seems to go back to the mean.\nFor the 3D plot of the density, we can see that the further the period ahead, the density is more dispersed since the data is become less informative as horizon increases."
  },
  {
    "objectID": "index.html#extended-model-1",
    "href": "index.html#extended-model-1",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Extended model",
    "text": "Extended model\n\n\n\n\nPosterior A means and sd table\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n\n0.115926\n0.960286\n-0.022171\n0.055828\n-0.162147\n-0.037312\n0.003495\n0.014091\n0.156084\n-0.051559\n0.007850\n0.006557\n0.035953\n0.028374\n0.002877\n0.003091\n-0.001119\n\n\n3.275994\n0.116849\n0.335168\n0.357329\n0.108210\n0.129094\n0.200902\n0.202319\n0.143380\n0.100559\n0.137834\n0.138374\n0.106336\n0.076114\n0.103254\n0.103780\n0.071334\n\n\n0.004895\n0.005701\n0.998517\n-0.000496\n0.001191\n0.001210\n-0.000214\n-0.000045\n0.000580\n-0.002378\n-0.000008\n-0.000057\n-0.000622\n-0.001180\n0.000046\n-0.000018\n-0.001231\n\n\n0.107518\n0.003856\n0.011049\n0.011727\n0.003546\n0.004281\n0.006580\n0.006677\n0.004737\n0.003309\n0.004513\n0.004514\n0.003508\n0.002501\n0.003412\n0.003432\n0.002348\n\n\n\n\n\n\n\n\n\n\nPosterior Sigma means and sd table\n\n\n1\n2\n3\n4\n\n\n\n\n0.176069\n-0.002084\n-0.000107\n-0.029468\n\n\n0.024486\n0.000601\n0.000060\n0.015250\n\n\n-0.002084\n0.000191\n0.000004\n0.000509\n\n\n0.000601\n0.000026\n0.000002\n0.000497\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe plot of forecast for the extended model doesn’t show any significant differences visually. The confidence interval narrowed insignificantly.\nThe data used is up to September 2023. The subsequent unemployment rate is released by the\n\n\n\n\nABS Data\n\n\nMonth\nABS\n\n\n\n\nOct-23\n3.8\n\n\nNov-23\n3.9\n\n\nDec-23\n4.0\n\n\nJan-24\n4.1\n\n\nFeb-24\n3.7\n\n\nMar-24\n3.9\n\n\nApr-24\n4.1\n\n\n\n\n\n\n\n\n\n\nForecast Data\n\n\nQuarter\nForecast\n\n\n\n\nQ4-23\n3.694583\n\n\nQ1-24\n3.868261\n\n\nQ2-24\n4.063661"
  },
  {
    "objectID": "index.html#extension-2",
    "href": "index.html#extension-2",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Extension 2",
    "text": "Extension 2\nWith 2 regime states, we would have \\(Y_m\\) and \\(X_m\\)\nThe full conditional joint posterior have the following form \\[\\begin{align}\np(A|Y,X,\\Sigma) &\\sim MN_{K \\times N}(\\overline{A}, \\Sigma,\\overline{V} ) \\\\\np(\\Sigma|Y,X) &\\sim IW_{N}(\\overline{S}, \\overline{v})\\\\\n\\\\\n\\overline{V_m} &= (X'X + \\underline{V}^{-1})^{-1} \\\\\n\\overline{A_m} &= \\overline{V_m}(X_m'Y_m+\\underline{V}^{-1}\\underline{A}) \\\\\n\\overline{v} &= T_m + \\underline{v} \\\\\n\\overline{S_m} &= \\underline{S}+Y_m'Y_m+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\\overline{A_m}'\n\\overline{V_m}^{-1}\\overline{A_m} \\\\\n\\end{align}\\]\nMarkov Switching Initial probability of regimes \\[\\begin{align}\n\\begin{bmatrix}\np_{1} & p_{2}\\\\\n\\end{bmatrix}\n\\end{align}\\]\nProbability transition matrix \\[\\begin{align}\n\\begin{bmatrix}\np_{11} & p_{12}\\\\\np_{21} & p_{22}\\\\\n\\end{bmatrix}\n\\end{align}\\]\n\\[\\begin{align}\n\\xi_{t} = \\begin{bmatrix}\n1\\\\\n0\\\\\n\\end{bmatrix}, if s_t = 1\n\\end{align}\\]\n\\[\\begin{align}\n\\xi_{t} = \\begin{bmatrix}\n0\\\\\n1\\\\\n\\end{bmatrix}, if s_t = 2\n\\end{align}\\] The posterior draws are done with Gibb sampling.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can check to see if the draws are correctly put in the correct regime, with regime 1 being regime with higher volatility, we can plot the sigmas of two regime."
  }
]