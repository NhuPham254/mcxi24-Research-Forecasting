[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "",
    "text": "Abstract. Research on how Bayesian VARs with regime change affect the forecasting of unemployment rate\nKeywords. bsvars, regime change, forecasting, R,"
  },
  {
    "objectID": "index.html#model",
    "href": "index.html#model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Model",
    "text": "Model\n\nHypothesis\nVar(p) model\n\\[\\begin{aligned}\ny_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 x_{1, t-1} + \\beta_3 x_{2, t-1} + \\ldots + \\beta_n x_{n, t-1} + \\varepsilon_t\n\\end{aligned}\\]\nVar(p) model with regime change, meaning time-varying parameters\n\\[\\begin{aligned}\ny_t &= \\beta_{0,S_t} + \\beta_{1,S_t} y_{t-1} + \\beta_{2,S_t} x_{1, t-1} + \\beta_{3,S_t} x_{2, t-1} + \\ldots + \\beta_{n,S_t} x_{n, t-1} + \\varepsilon_t \\\\\n\\end{aligned}\\]\nProbability of transitioning from one state to another\n\\[\\begin{aligned}\nP(S_t = j | S_{t-1} = i) &= \\pi_{ij}\n\\end{aligned}\\]\n\n\nMatrix form\n\\[\\begin{align*}\n\\mathbf{Y}_t = \\boldsymbol{\\beta}_{S_t} \\mathbf{X}_t + \\boldsymbol{E}_t\n\\end{align*}\\]\n\\[\\begin{align*}\n\\boldsymbol{E}_t\n\\sim MN(0_T, \\Sigma, I_T)\n\\end{align*}\\]\n\\begin{align*} \\mathbf{Y}_t & : \\text{Matrix of response variables} \\\\ \\boldsymbol{\\beta} & : \\text{Coefficient matrix corresponding to regime state} \\\\ S_t & : \\text{Regime state} \\\\ \\mathbf{X}_t & : \\text{Matrix of predictor variables} \\\\ \\boldsymbol{\\varepsilon}_t & : \\text{Error term vector} \\end{align*}\n\\begin{align*} \\mathbf{Y}_t = \\begin{pmatrix} \\text{Unemployment}_t \\\\ \\text{GDP}_t \\\\ \\text{WPI}_t \\\\ \\text{CashRate}_t \\\\ \\end{pmatrix} \\end{align*}\nThe model’s equations include time-varying parameters, such as the coefficients of lagged variables, which adapt to changing economic conditions."
  },
  {
    "objectID": "index.html#basic-model",
    "href": "index.html#basic-model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Basic Model",
    "text": "Basic Model\nThe model follows the Normal Inverse Wishart distribution.\nLikelihood function kernel \\[\\begin{align}\nL(A,\\Sigma|Y,X) \\propto det(\\Sigma)^{-\\frac{T}{2}}exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\}\n\\end{align}\\]\n\nMinnesota Prior distribution\nThe Minnesota prior is commonly used in Bayesian Vector Autoregression (BVAR) models due to its ability to impose shrinkage towards zero on the coefficients, effectively regularizing the estimation process. The Minnesota prior aligns effectively with the stylized fact of nonstationarity observed in macroeconomic variables.\n\\[\\begin{align*}\np(A, \\Sigma) = p(A \\mid \\Sigma) \\cdot p(\\Sigma) \\\\\nA \\mid \\Sigma \\sim \\text{MN}_{K \\times N} (\\underline{A}, \\Sigma, \\underline{V}) \\\\\n\\Sigma \\sim  \\text{IW}_{N} (\\underline{S}, \\underline{v})\\\\\n\\end{align*}\\]\nWith lags = 4 and N = 4\n\\[\\begin{align*}\n\\underline{A} = \\begin{bmatrix}\n\\mathbf{0}_{4 \\times 1} & \\mathbf{I}_{4} & \\mathbf{0}_{4 \\times (4-1)4}\n\\end{bmatrix}'\n= \\begin{bmatrix}\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n\\end{bmatrix}'\n\\end{align*}\\]\nThe column-specific prior covariance of A \\[\\begin{align*}\n\\underline{V} &= \\text{diag}\\left( \\begin{bmatrix}\nk_2 & k_1(\\mathbf{p}^{-2} \\otimes 1'_4)\n\\end{bmatrix} \\right)\\\\\n\\mathbf{p} &= \\begin{bmatrix}\n1 & 2 & 3 & 4 \\\\\n\\end{bmatrix}\n\\end{align*}\\] \\[\\begin{align*}\n& k_2 : \\text{overall shrinkage for the constant term} \\\\\n& k_1 : \\text{overall shrinkage levels for autoregressive slopes} \\\\\n\\end{align*}\\]\nPrior covariance matrix\n\\[\\begin{bmatrix}\nk_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & k_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & k_1 & 0 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & k_1 & 0 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & k_1 & 0 & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & 0 & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & 0 & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & 0 & \\cdots & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{4} & \\cdots & 0\\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & \\frac{k_1}{16}      \n\\end{bmatrix}\\]\n\n\nThe joint posterior distribution\n\\[\\begin{align*}\np(A,\\Sigma|Y,X) &\\propto L(A,\\Sigma|Y,X)p(A,\\Sigma) \\\\\n&= L(A,\\Sigma|Y,X)p(A|\\Sigma)p(\\Sigma)\n\\end{align*}\\]\n\\[\\begin{align}\np(A,\\Sigma|Y,X) &\\propto \\det(\\Sigma)^{-\\frac{T}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(Y-XA)'(Y-XA)]\\} \\\\\n&\\times \\det(\\Sigma)^{-\\frac{N+K+\\underline{v}+1}{2}} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}(A-\\underline{A}) \\underline{V}^{-1}(A-\\underline{A})]\\} \\\\\n&\\times exp\\{-\\frac{1}{2}tr[\\Sigma^{-1}\\underline{S}]\\}\n\\end{align}\\]\nThe full conditional joint posterior have the following form \\[\\begin{align}\np(A|Y,X,\\Sigma) &\\sim MN_{K \\times N}(\\overline{A}, \\Sigma,\\overline{V} ) \\\\\np(\\Sigma|Y,X) &\\sim IW_{N}(\\overline{S}, \\overline{v})\\\\\n\\\\\n\\overline{V} &= (X'X + \\underline{V}^{-1})^{-1} \\\\\n\\overline{A} &= \\overline{V}(X'Y+\\underline{V}^{-1}\\underline{A}) \\\\\n\\overline{v} &= T + \\underline{v} \\\\\n\\overline{S} &= \\underline{S}+Y'Y+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\\overline{A}'\n\\overline{V}^{-1}\\overline{A} \\\\\n\\end{align}\\]\n\n###############################################\n# Posterior draws Normal-inverse Wishart\n###############################################\nposterior_draws       = function (S, Y, X, A.prior, V.prior, S.prior, nu.prior){\n    # Posterior parameters\n    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))\n    V.bar             = solve(V.bar.inv)\n    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)\n    nu.bar            = nrow(Y) + nu.prior\n    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior -\n                        t(A.bar)%*%V.bar.inv%*%A.bar\n    S.bar.inv         = solve(S.bar)\n  \n    # Posterior draws \n    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n    Sigma.posterior   = apply(Sigma.posterior,3,solve)\n    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))\n    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))\n    L                 = t(chol(V.bar))\n    for (s in 1:S){\n      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])\n    }\n \n    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)\n    return(output)\n}\n\nsample_minnesota        = posterior_draws(S=50000, Y, X, A.prior, V.prior, S.prior, nu.prior)\nsample_minnesota_A      = sample_minnesota$A.posterior\nsample_minnesota_Sigma  = sample_minnesota$Sigma.posterior"
  },
  {
    "objectID": "index.html#extension-1-model",
    "href": "index.html#extension-1-model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Extension 1 Model",
    "text": "Extension 1 Model\nCointegration is when the non-stationary variables have an equilibrium long term relationship or a common trend. The model is extended to incorporate dummy-observation-prior, aiming to account for the potential cointegration amongst the variables, capturing the underlying economic relationships and dynamics.\nThis approach allows us to leverage both the observed data and additional information about the structural relationships among variables, leading to more accurate parameter estimation and potentially improved forecasting performance.\nDummy observation prior also known as known as “sum-of-coefficients” proposed by Doan, Litterman, and Sims (1984) required a set of artificial observations for each variable.\n\\[\\begin{align*}\n\\underset{4\\times 4}y^{+} &= diag(\\frac{\\overline{y_0}}{\\mu}) \\\\\n\\underset{4 \\times (1+4\\times 4)}{x^{+}} &= [\\underset{n \\times 1}0,y^{+},...,y^{+}]\n\\end{align*}\\]\nTo be consistent with cointegration, an additional prior proposed by Sims (1993) is also added.\n\\[\\begin{align*}\n\\underset{1\\times 4}y^{++} &= \\frac{\\overline{y_0}^{'}}{\\delta}, ,   \\ i =1,2,3,4\\\\\n\\underset{1 \\times (1+4\\times 4)}{x^{++}} &= [\\frac{1}{\\delta},y^{++},...,y^{++}]\\\\\n\\end{align*}\\] \\[\\begin{align*}\n& \\overline{y_0} : \\text{average of the first 4 lag observations for each variable}\\\\\n& \\mu: \\text{controls variance }\\\\\n& \\delta: \\text{controls the tightness of the prior}\n\\end{align*}\\]\nFrom the above, the following matrix form is created:\n\\[\\begin{align*}\nY^{+} & = \\begin{bmatrix} y^+ \\\\ y^{++}\\end{bmatrix}', X^{+}  = \\begin{bmatrix} x^+ \\\\ x^{++}\\end{bmatrix}'\\\\\nY^{+} & = X^{+}A+E^{+} \\\\\nY^{+} & = \\begin{bmatrix}\n\\frac{\\overline{y_0}_1}{\\mu} & 0 & 0 & 0 \\\\\n0 & \\frac{\\overline{y_0}_2}{\\mu} & 0 & 0 \\\\\n0 & 0 & \\frac{\\overline{y_0}_3}{\\mu} & 0 \\\\\n0 & 0 & 0 & \\frac{\\overline{y_0}_4}{\\mu} \\\\\n\\frac{\\overline{y_0}_1}{\\delta} & \\frac{\\overline{y_0}_2}{\\delta} & \\frac{\\overline{y_0}_3}{\\delta} & \\frac{\\overline{y_0}_4}{\\delta} \\\\\n\\end{bmatrix}\n\\end{align*}\\]\n\\[\\begin{align*}\nX^{+} = \\begin{bmatrix}\n0 & \\frac{\\overline{y_0}_1}{\\mu} & 0 & 0 & 0 & \\cdots & 0 \\\\\n0 & 0 & \\frac{\\overline{y_0}_2}{\\mu} & 0 & 0 & \\cdots & 0 \\\\\n0 & 0 & 0 & \\frac{\\overline{y_0}_3}{\\mu} & 0 & \\cdots & 0 \\\\\n0 & 0 & 0 & 0 & \\frac{\\overline{y_0}_4}{\\mu} & \\cdots & \\frac{\\overline{y_0}_4}{\\mu} \\\\\n\\frac{1}{\\delta} & \\frac{\\overline{y_0}_1}{\\delta} & \\frac{\\overline{y_0}_2}{\\delta} & \\frac{\\overline{y_0}_3}{\\delta} & \\frac{\\overline{y_0}_4}{\\delta} & \\cdots & \\frac{\\overline{y_0}_4}{\\delta} \\\\\n\\end{bmatrix}\n\\end{align*}\\]\nThe prior distribution is\n\\[\\begin{align*}\nA \\mid \\Sigma &\\sim \\text{MN}_{K \\times N} (\\underline{A}^{+}, \\Sigma, \\underline{V}^{+}) \\\\\n\\Sigma &\\sim  \\text{IW}_{N} (\\underline{S}^{+}, \\underline{v}^{+})\\\\\n\\\\\n\\underline{A}^{+} &= (X^{+'}X )^{-1}X^{+'}Y^{+} \\\\\n\\underline{V}^{+} &= (X^{+'}X )^{-1} \\\\\n\\underline{v}^{+} &= T^{+} - K - N - 1\\\\\n\\underline{S}^{+} &= (Y^{+}-X^{+}\\underline{A}^{+})^{'}(Y^{+}-X^{+}\\underline{A}^{+})\\\\\n\\end{align*}\\]\n\nMinnesota and dummy observation prior distribution\nThe newly created matrix specified the model has 5 dummy observations. The above prior distribution is likely to encounter the problem of not having enough observations and lead to many challenges to meet the requirements for degree of freedom or invertibility of matrices. To resolve this, the combination of specifying the prior through both Normal inverse Wishart and dummy-observations is proposed, which is detived similarly to the posterior distribution in the basic model.\n\\[\\begin{align*}\nA \\mid \\Sigma &\\sim \\text{MN}_{K \\times N} (\\widetilde{A}, \\Sigma, \\widetilde{V}) \\\\\n\\Sigma &\\sim  \\text{IW}_{N} (\\widetilde{S}, \\widetilde{v})\\\\\n\\\\\n\\widetilde{A} &= \\widetilde{V}(X^{+'}Y^{+}+\\underline{V}^{-1}\\underline{A}) \\\\\n\\widetilde{V} &= (X^{+'}X^{+} + \\underline{V}^{-1})^{-1} \\\\\n\\widetilde{v} &= T^{+} + \\underline{v} \\\\\n\\widetilde{S} &= \\underline{S}+Y^{+'}Y^{+}+\\underline{A}'\\underline{V}^{-1}\\underline{A} -\\widetilde{A}'\\widetilde{V}^{-1}\\widetilde{A} \\\\\n\\end{align*}\\]\nThe full conditional joint posterior have the following form \\[\\begin{align}\np(A|Y,X,\\Sigma) &\\sim MN_{K \\times N}(\\overline{A}, \\Sigma,\\overline{V} ) \\\\\np(\\Sigma|Y,X) &\\sim IW_{N}(\\overline{S}, \\overline{v})\\\\\n\\\\\n\\overline{V} &= (X'X + \\widetilde{V}^{-1})^{-1} \\\\\n\\overline{A} &= \\overline{V}(X'Y+\\widetilde{V}^{-1}\\widetilde{A}) \\\\\n\\overline{v} &= T + \\widetilde{v} \\\\\n\\overline{S} &= \\widetilde{S}+Y'Y+\\widetilde{A}'\\widetilde{V}^{-1}\\widetilde{A}-\\overline{A}'\n\\overline{V}^{-1}\\overline{A} \\\\\n\\end{align}\\]\n\n###############################################\n# Posterior draws for dummy prior\n###############################################\nposterior_draws_dummy = function(S, Y, X, A.prior, V.prior, S.prior, nu.prior) {\n  \n  N       = ncol(Y)\n  p       = (ncol(X) - 1)/N\n  mu      = 1000\n  delta   = 1000\n  dim(X)\n  avg_unmp &lt;- mean(X[1, c(2, 6, 10, 14)])\n  avg_gdp &lt;- mean(X[1, c(3, 7, 11, 15)])\n  avg_wpi &lt;- mean(X[1, c(4, 8, 12, 16)])\n  avg_cash &lt;- mean(X[1, c(5, 9, 13, 17)])\n  \n  diag_mu &lt;- diag(c(avg_unmp/mu, avg_gdp/mu, avg_wpi/mu, avg_cash/mu))\n  row_delta &lt;-  matrix(c(avg_unmp/delta, avg_gdp/delta, avg_wpi/delta, avg_cash/delta), nrow = 1)\n  \n  Y_d       = rbind(diag_mu, row_delta)\n  \n  first_vector &lt;- matrix(c(0,0,0,0, 1/delta), ncol = 1)\n  X_d      = cbind(first_vector, Y_d, Y_d, Y_d, Y_d)\n  \n  # Normal-inverse Wishart combination of specifying the prior \n  ############################################################\n  V.tilde.inv   = t(X_d)%*%X_d + diag(1/diag(V.prior))\n  V.tilde       = solve(V.tilde.inv)\n  A.tilde       = V.tilde%*%(t(X_d)%*%Y_d + diag(1/diag(V.prior))%*%A.prior)\n  nu.tilde      = nrow(Y_d) + nu.prior\n  S.tilde       = S.prior + t(Y_d)%*%Y_d + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior -\n    t(A.tilde)%*%V.tilde.inv%*%A.tilde\n  S.tilde.inv   = solve(S.tilde)\n\n  # Normal-inverse Wishart posterior parameters\n  V.bar.inv   = t(X)%*%X + diag(1/diag(V.tilde))\n  V.bar       = solve(V.bar.inv)\n  A.bar       = V.bar%*%(t(X)%*%Y + diag(1/diag(V.tilde))%*%A.tilde)\n  nu.bar      = nrow(Y) + nu.tilde\n  S.bar       = S.tilde + t(Y)%*%Y + t(A.tilde)%*%diag(1/diag(V.tilde))%*%A.tilde -\n                t(A.bar)%*%V.bar.inv%*%A.bar\n  S.bar.inv   = solve(S.bar)\n  \n\n  # Posterior draws \n  Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)\n  Sigma.posterior   = apply(Sigma.posterior,3,solve)\n  Sigma.posterior   = array(Sigma.posterior,c(N,N,S))\n  A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))\n  L                 = t(chol(V.bar))\n  for (s in 1:S){\n    A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])\n    }\n  output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)\n  return(output)\n}\nsample_dummy        = posterior_draws_dummy(S = 50000, Y, X, A.prior, V.prior, S.prior, nu.prior)\nsample_dummy_A      = sample_dummy$A.posterior\nsample_dummy_Sigma  = sample_dummy$Sigma.posterior"
  },
  {
    "objectID": "index.html#basic-model-1",
    "href": "index.html#basic-model-1",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Basic model",
    "text": "Basic model\n\nposterior_summary &lt;- function(sample) {\n  # Report posterior means and sd of parameters\n  A.E &lt;- round(apply(sample$A.posterior, 1:2, mean), 6)\n  A.sd &lt;- round(apply(sample$A.posterior, 1:2, sd), 6)\n  Sigma.E &lt;- round(apply(sample$Sigma.posterior, 1:2, mean), 6)\n  Sigma.sd &lt;- round(apply(sample$Sigma.posterior, 1:2, sd), 6)\n  \n  # Create tables\n  A_table &lt;- data.frame(rbind(t(A.E)[1,], t(A.sd)[1,], t(A.E)[2,], t(A.sd)[2,]))\n  Sigma_table &lt;- data.frame(rbind(t(Sigma.E)[1,], t(Sigma.sd)[1,], t(Sigma.E)[2,],\n                                  t(Sigma.sd)[2,]))\n  # Format tables using kable\n  A_table_html &lt;- kable(A_table, format = \"html\", caption = \"Posterior A means and sd table\",\n                        col.names = paste0(1:ncol(A_table)))\n  Sigma_table_html &lt;- kable(Sigma_table, format = \"html\", caption = \"Posterior Sigma means and sd\n                            table\", col.names = paste0(1:ncol(Sigma_table)))\n  \n  # Return tables as list\n  return(A_table_html, Sigma_table_html)\n}\n  \n\n############################################################\n# Point forecasts 2D plot\nforecast_plots &lt;- function(Y, Y.h, h, theta, phi, xlim) {\n  \n  # Define colors\n  mcxs1  = \"#05386B\"\n  mcxs2  = \"#379683\"\n  mcxs3  = \"#5CDB95\"\n  mcxs4  = \"#8EE4AF\"\n  mcxs5  = \"#EDF5E1\"\n  \n  mcxs1.rgb   = col2rgb(mcxs1)\n  mcxs1.shade1= rgb(mcxs1.rgb[1],mcxs1.rgb[2],mcxs1.rgb[3], alpha=50, maxColorValue=255)\n  mcxs2.rgb   = col2rgb(mcxs2)\n  mcxs2.shade1= rgb(mcxs2.rgb[1],mcxs2.rgb[2],mcxs2.rgb[3], alpha=50, maxColorValue=255)\n  \n  point_forecast    = apply(Y.h[,1,],1,mean) \n  interval_forecast = apply(Y.h[,1,],1,hdi,credMass=0.90)\n  interval_forecast_1 = apply(Y.h[,1,],1,hdi,credMass=0.68)\n  range             = range(Y[,1],interval_forecast)\n  \n  par(mfrow=c(1,1), mar=rep(3,4),cex.axis=1)\n  plot(1:(length(Y[,1])), Y[,1], type=\"l\", axes=FALSE, \n       xlim = c(1, nrow(Y)+h), ylim=range, \n       xlab=\"\", ylab=\"\", \n       lwd=2, col = mcxs1)\n  lines(length(Y[,1]):(length(Y[,1]) + h), c(Y[nrow(Y), 1],point_forecast), type=\"l\", \n        xlim = c(1, nrow(Y)+h), ylim=range,\n        xlab=\"\", ylab=\"\", \n        lwd=2, col = mcxs2)\n  axis(1,c(3,23,43,63,83,101,nrow(Y), nrow(Y)+h),\n       c(\"1999\",\"2003\",\"2008\",\"20013\",\"2018\",\"2023\",\"\", \"2028\"), \n       col=\"black\")\n  axis(2, at=seq(from=range[1], to=range[2], length.out=5), \n       labels=round(seq(from=range[1], to=range[2], length.out=5), 2),\n       col=\"black\")\n  end_y_value &lt;- point_forecast[13] \n  abline(h = end_y_value, col=\"red\", lty=2, lwd=1)\n  abline(v = nrow(Y), col = \"black\")\n  legend(\"bottomleft\", legend=c(\"Data\", \"Forecast\"), \n         col=c(mcxs1, mcxs2), lty=c(1, 1), lwd=c(2, 2))\n  polygon(c(length(Y[,1]):(length(Y[,1]) + h), (length(Y[,1]):(length(Y[,1]) + h))[(h+1):1]), \n          c(Y[nrow(Y), 1], interval_forecast[1,], interval_forecast[2,h:1], Y[nrow(Y), 1]), \n          col = mcxs1.shade1, border = mcxs1.shade1)\n  polygon(c(length(Y[,1]):(length(Y[,1]) + h), (length(Y[,1]):(length(Y[,1]) + h))[(h+1):1]), \n          c(Y[nrow(Y), 1], interval_forecast_1[1,], interval_forecast_1[2,h:1], Y[nrow(Y), 1]), \n          col = mcxs1.shade1, border = mcxs1.shade1)\n  \n  limits.1    = range(Y.h[,1,])\n  point.f     = apply(Y.h[,1,],1,mean)\n  interval.f  = apply(Y.h[,1,],1,hdi,credMass=0.90)\n  \n  x           = seq(from=limits.1[1], to=limits.1[2], length.out=100)\n  z           = matrix(NA,h,99)\n  for (i in 1:h){\n    z[i,]     = hist(Y.h[i,1,], breaks=x, plot=FALSE)$density\n  }\n  x           = hist(Y.h[i,1,], breaks=x, plot=FALSE)$mids\n  yy          = 1:h\n  z           = t(z)\n  \n  # Adjust xlim, ylim, zlim based on h\n  xlim &lt;- c(limits.1[1], limits.1[2])\n  ylim &lt;- c(1, h)\n  zlim &lt;- range(z)\n  \n  f4 &lt;- persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab=\"\\nunmp[t+h|t]\", ylab=\"h\",\n                zlab=\"\\npredictive densities of unemployment rate\", shade=NA, border=NA,\n                ticktype=\"detailed\", nticks=3,cex.lab=1, col=NA, plot=FALSE, \n                xlim = xlim, ylim = ylim, zlim = zlim)\n  \n  perspbox(x=x, y=yy, z=z, bty=\"f\", col.axis=\"black\", phi=phi, theta=theta,\n           xlab=\"\\nunemployment[t+h|t]\", ylab=\"h\", zlab=\"\\npredictive densities of unemployment rate\",\n           ticktype=\"detailed\", nticks=3, cex.lab=1, col = NULL, plot = TRUE, \n           xlim = xlim, ylim = ylim, zlim = zlim)\n  \n  polygon3D(x = c(interval.f[1,], interval.f[2,h:1]), y = c(1:h, h:1), z = rep(0, 2*h), \n            col = mcxs1.shade1, NAcol = \"white\", border = NA, add = TRUE, plot = TRUE, \n            xlim = xlim, ylim = ylim, zlim = zlim)\n  \n  for (i in 1:h){\n    f4.l &lt;- trans3d(x = x, y = yy[i], z = z[,i], pmat = f4)\n    lines(f4.l, lwd = 0.5, col = \"black\")\n  }\n  \n  f4.l1 &lt;- trans3d(x = point.f, y = yy, z = 0, pmat = f4)\n  lines(f4.l1, lwd = 2, col = mcxs1)\n}\n\nforecast &lt;- function(S, sample_A, sample_Sigma, Y, p, h) {\n  # Initialize the array to store forecasts\n  Y.h &lt;- array(NA, c(h, N, S))\n  \n  # Loop over each sample\n  for (s in 1:S) {\n    A.posterior.draw &lt;- sample_A[,,s]\n    Sigma.posterior &lt;- sample_Sigma[,,s]\n    x.Ti &lt;- Y[(nrow(Y) - p + 1):nrow(Y),]\n    x.Ti &lt;- x.Ti[p:1,]\n    \n    # Forecast h steps ahead\n    for (i in 1:h) {\n      x.T &lt;- c(1, as.vector(t(x.Ti)))\n      Y.f &lt;- rmvnorm(1, mean = x.T %*% A.posterior.draw, sigma = Sigma.posterior)\n      x.Ti &lt;- rbind(Y.f, x.Ti[1:(p - 1),])\n      Y.h[i,,s] &lt;- Y.f[1:2]\n    }\n  }\n  \n  return(Y.h)\n}\n\nSimulate draws from the predictive density\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe plot of point forecast and density for 13 periods ahead, equivalent to 13 quarters or 3 years and 1 quarter from Q4 2023 to Q4 2026 shows a clear upward trend. The confidence interval is quite large. The unemployment rate seems to go back to the mean.\nFor the 3D plot of the density, we can see that the further the period ahead, the density is more dispersed since the data is become less informative as horizon increases."
  },
  {
    "objectID": "index.html#extended-model",
    "href": "index.html#extended-model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Extended model",
    "text": "Extended model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe plot of forecast for the extended model doesn’t show any significant differences visually. The confidence interval narrowed insignificantly.\nThe data used is up to September 2023. The subsequent unemployment rate is released by the\n\n\n\n\nABS Data\n\n\nMonth\nABS\n\n\n\n\nOct-23\n3.8\n\n\nNov-23\n3.9\n\n\nDec-23\n4.0\n\n\nJan-24\n4.1\n\n\nFeb-24\n3.7\n\n\nMar-24\n3.9\n\n\nApr-24\n4.1\n\n\n\n\n\n\n\n\n\n\nForecast Data\n\n\nQuarter\nForecast\n\n\n\n\nQ4-23\n3.694583\n\n\nQ1-24\n3.868261\n\n\nQ2-24\n4.063661"
  },
  {
    "objectID": "index.html#extension-2---regime-change",
    "href": "index.html#extension-2---regime-change",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Extension 2 - Regime change",
    "text": "Extension 2 - Regime change\nWith 2 regime states, we would have \\(Y_m\\) and \\(X_m\\)\nThe full conditional joint posterior have the following form \\[\\begin{align}\np(A|Y,X,\\Sigma) &\\sim MN_{K \\times N}(\\overline{A}, \\Sigma,\\overline{V} ) \\\\\np(\\Sigma|Y,X) &\\sim IW_{N}(\\overline{S}, \\overline{v})\\\\\n\\\\\n\\overline{V_m} &= (X'X + \\underline{V}^{-1})^{-1} \\\\\n\\overline{A_m} &= \\overline{V_m}(X_m'Y_m+\\underline{V}^{-1}\\underline{A}) \\\\\n\\overline{v} &= T_m + \\underline{v} \\\\\n\\overline{S_m} &= \\underline{S}+Y_m'Y_m+\\underline{A}'\\underline{V}^{-1}\\underline{A}-\\overline{A_m}'\n\\overline{V_m}^{-1}\\overline{A_m} \\\\\n\\end{align}\\]\nMarkov Switching Initial probability of regimes \\[\\begin{align}\n\\begin{bmatrix}\np_{1} & p_{2}\\\\\n\\end{bmatrix}\n\\end{align}\\]\nProbability transition matrix \\[\\begin{align}\n\\begin{bmatrix}\np_{11} & p_{12}\\\\\np_{21} & p_{22}\\\\\n\\end{bmatrix}\n\\end{align}\\]\n\\[\\begin{align}\n\\xi_{t} = \\begin{bmatrix}\n1\\\\\n0\\\\\n\\end{bmatrix}, if s_t = 1\n\\end{align}\\]\n\\[\\begin{align}\n\\xi_{t} = \\begin{bmatrix}\n0\\\\\n1\\\\\n\\end{bmatrix}, if s_t = 2\n\\end{align}\\] The posterior draws are done with Gibb sampling.\nTo examine how the regime draws are distributed between the two states, we visualize the switching variable \\(\\xi\\). Initially, the plot suggests that the regime assignments appear arbitrary. To address this issue, a label switching procedure is implemented to ensure consitency in how the two regimes are identified, in this case regime 1 is identified as the state with higher volatility. Following the label switching, the distinction between the two regimes becomes more evident. The drawn regimes indicate that regime 1 corresponds to the period around 2020, which aligns with the Covid-19 pandemic. This finding is intuitive as the Covid-19 pandemic significantly impacted the economy at large, including unemployment rates. Regime 2, on the other hand, represents other periods.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfter the regimes are correctly placed, we can forecast h-step ahead using the posterior draws.\n\nMarkov_forecast &lt;- function(S, sample, Y, p, h) {\n  N &lt;- ncol(Y)\n  # Initialize the array to store forecasts\n  Y.h = array(NA, c(h, 2, S))\n\n  for (s in 1:S){\n    A.posterior.draw1 = sample$A.posterior1[,,s]\n    A.posterior.draw2 = sample$A.posterior2[,,s]\n    Sigma.posterior1 = sample$Sigma.posterior1[,,s]\n    Sigma.posterior2 = sample$Sigma.posterior2[,,s]\n  \n    T = dim(sample$xi)[2]\n  \n    x.Ti = Y[(nrow(Y)-p+1):nrow(Y),]\n    x.Ti = x.Ti[p:1,]\n    \n    P_h = sample$P[,,s] %*% sample$xi[,T,s]  # Initializing P_h\n  \n    for (i in 1:h){\n      x.T = c(1, as.vector(t(x.Ti)))\n    \n      if (i &gt; 1) {  # Only update P_h if i &gt; 1\n        P_h = sample$P[,,s] %*% P_h\n      }\n      sample_m = sample.int(2,1, prob=as.numeric(P_h))\n    \n      if (sample_m == 1) {\n        A.posterior.draw = A.posterior.draw1\n        Sigma.posterior = Sigma.posterior1\n      } else {\n        A.posterior.draw = A.posterior.draw2\n        Sigma.posterior = Sigma.posterior2\n      }\n    \n      Y.f = rmvnorm(1, mean = x.T %*% A.posterior.draw, sigma = Sigma.posterior)\n      x.Ti = rbind(Y.f, x.Ti[1:(p-1),])\n      Y.h[i,,s] = Y.f[1:2]\n    }\n  }\n  return(Y.h)\n}\n\nThe plot below shows the forecast using Minnesota prior and regime change for unemployment rate."
  },
  {
    "objectID": "index.html#final-model",
    "href": "index.html#final-model",
    "title": "Forecasting Unemployment rate using Bayesian VARs with Regime change",
    "section": "Final model",
    "text": "Final model\nThe final model is the combination of Minnesota prior, dummy observation prior and regime change to account for heteroskedasticity.\nSimilarly to the baseline model, the prior will be a combination of Minnesota and dummy observation prior. Then the Markov-switching Gibb-sampling is done with these new priors to obtain posterior draws"
  }
]